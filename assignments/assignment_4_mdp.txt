The Problems Given to You

You are being asked to explore Markov Decision Processes (MDPs):

Come up with two interesting MDPs.

Explain why they are interesting.

They don't need to be overly complicated or directly grounded in a real situation,
but it will be worthwhile if your MDPs are inspired by some process you are interested in
or are familiar with.
It's ok to keep it somewhat simple.
For the purposes of this assignment, though, make sure one has a "small" number of states,
and the other has a "large" number of states.

Solve each MDP using value iteration as well as policy iteration.

How many iterations does it take to converge?
Which one converges faster?
Why?
Do they converge to the same answer?
How did the number of states affect things, if at all?

Now pick your favorite reinforcement learning algorithm and use it to solve the two MDPs.
How does it perform, especially in comparison to the cases above where you knew
the model, rewards, and so on?

What exploration strategies did you choose? Did some work better than others?